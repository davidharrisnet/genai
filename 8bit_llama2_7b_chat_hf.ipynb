{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyO/YJrNmVhx/Xs3A4PEwPns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a3e17f8494064a92ab4bc31727a637b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3421bb2919d84261a313e87a0db24780",
              "IPY_MODEL_b3dcf3097fae4c2ba62ae504f159cd04",
              "IPY_MODEL_89f6f3d3a5b3489cbdb20e6094cdf5c5"
            ],
            "layout": "IPY_MODEL_f37702cda9914a22b1d92abffd31feb2"
          }
        },
        "3421bb2919d84261a313e87a0db24780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb0f57e303544e3390bbbce005170efd",
            "placeholder": "​",
            "style": "IPY_MODEL_c0fecad26b5b4847a7f0d4bf41462454",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b3dcf3097fae4c2ba62ae504f159cd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28553707bce74a33bae16fbbadc3f30c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00151f17de8046f6ae1ad88596b8e844",
            "value": 2
          }
        },
        "89f6f3d3a5b3489cbdb20e6094cdf5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53ec3292c3cd497d80926f9c644f4db9",
            "placeholder": "​",
            "style": "IPY_MODEL_119101e5f0b44ab8a58850c689503118",
            "value": " 2/2 [03:41&lt;00:00, 100.87s/it]"
          }
        },
        "f37702cda9914a22b1d92abffd31feb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0f57e303544e3390bbbce005170efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0fecad26b5b4847a7f0d4bf41462454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28553707bce74a33bae16fbbadc3f30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00151f17de8046f6ae1ad88596b8e844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53ec3292c3cd497d80926f9c644f4db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119101e5f0b44ab8a58850c689503118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidharrisnet/genai/blob/main/8bit_llama2_7b_chat_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIAfaF7S0tLf",
        "outputId": "61aba580-84bb-4dc1-c4ce-0c256ab71046"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/2.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l99DFGUt9BPw",
        "outputId": "65ffb9c5-1cfa-445f-8e27-888cfe8e4c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate einops  xformers bitsandbytes --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch import cuda, bfloat16\n",
        "from time import time\n",
        "import transformers\n",
        "import torch"
      ],
      "metadata": {
        "id": "mjmFcuwxoEks"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCpkNyNi9tJs",
        "outputId": "8b0f18d0-00dc-4e8d-e459-89d93896b4f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = os.path.join(\"/content\",\"drive\",\"My Drive\", \"models\", \"Llama-2-7b-chat-hf\", \"snapshots\", \"1\")"
      ],
      "metadata": {
        "id": "snoBKtwk9tya"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists(model_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GmCD2jXORxi",
        "outputId": "df216fcf-aa68-4183-e169-8b9f2a98554a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTQConfig"
      ],
      "metadata": {
        "id": "Zaw-pmn72r3v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
      ],
      "metadata": {
        "id": "LqiGzrbO2u35"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", load_in_8bit=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a3e17f8494064a92ab4bc31727a637b8",
            "3421bb2919d84261a313e87a0db24780",
            "b3dcf3097fae4c2ba62ae504f159cd04",
            "89f6f3d3a5b3489cbdb20e6094cdf5c5",
            "f37702cda9914a22b1d92abffd31feb2",
            "fb0f57e303544e3390bbbce005170efd",
            "c0fecad26b5b4847a7f0d4bf41462454",
            "28553707bce74a33bae16fbbadc3f30c",
            "00151f17de8046f6ae1ad88596b8e844",
            "53ec3292c3cd497d80926f9c644f4db9",
            "119101e5f0b44ab8a58850c689503118"
          ]
        },
        "id": "t_e3zkY7CYkv",
        "outputId": "e9d15cfa-8dab-4e97-d9bb-289c37f6b2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3e17f8494064a92ab4bc31727a637b8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_memory_footprint())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1w2krAH8Ix1",
        "outputId": "107b03bc-8da4-4998-bb3f-1088a1e53f73"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7067942912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_1 = time()\n",
        "query_pipeline = transformers.pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",)\n",
        "time_2 = time()\n",
        "print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41-k7dIJ-a-n",
        "outputId": "0c526c6a-d716-4b48-8962-6445007a1157"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare pipeline: 3.561 sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(tokenizer, pipeline, prompt_to_test):\n",
        "    \"\"\"\n",
        "    Perform a query\n",
        "    print the result\n",
        "    Args:\n",
        "        tokenizer: the tokenizer\n",
        "        pipeline: the pipeline\n",
        "        prompt_to_test: the prompt\n",
        "    Returns\n",
        "        None\n",
        "    \"\"\"\n",
        "    # adapted from https://huggingface.co/blog/llama2#using-transformers\n",
        "    time_1 = time()\n",
        "    sequences = pipeline(\n",
        "        prompt_to_test,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        max_length=2000,)\n",
        "    time_2 = time()\n",
        "    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n",
        "    for seq in sequences:\n",
        "        print(f\"Result: {seq['generated_text']}\")"
      ],
      "metadata": {
        "id": "5rIxXoIH-sH-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [ \"Write me a detailed scenario for a potential Russian invasion of Moldova.\",\n",
        "\n",
        "\"Now identify one person in this scenario who would be a potential HUMINT source for the US Intelligence Community and write a short source dossier. Be sure to include their placement and access.\",\n",
        "\"Write me three short intelligence information reports that came from that source about various events in the scenario.\",\n",
        "\"Add dates and times for the intelligence reports.\" ]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CZlfxTu0-wTv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(tokenizer,\n",
        "           query_pipeline,\n",
        "           questions[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U_VJ3aQIIyv",
        "outputId": "589100c7-e95e-4dd4-dbe0-605f34761e1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test inference: 215.787 sec.\n",
            "Result: Write me a detailed scenario for a potential Russian invasion of Moldova.\n",
            "Moldova, a small, landlocked country located between Ukraine and Romania, has been a source of tension between Russia and the West for several years. In recent months, Russia has increased its military presence along Moldova's borders, and there have been reports of Russian-backed separatist groups in the country's breakaway region of Transnistria.\n",
            "As tensions escalate, the Moldovan government has appealed to the international community for help in defending against a potential Russian invasion. The United States and other Western countries have pledged to provide military aid and support to Moldova, but it remains to be seen whether this will be enough to deter Russia's aggressive actions.\n",
            "Here is a potential scenario for a Russian invasion of Moldova:\n",
            "Scenario: Russian Invasion of Moldova\n",
            "Date: March 20, 2023\n",
            "Location: Moldova\n",
            "Objective: To secure control over Moldova's territory and resources, and to quell any opposition from the Moldovan government and its Western backers.\n",
            "Russian Forces:\n",
            "\n",
            "* 100,000 troops, including ground troops, air force, and naval assets\n",
            "* 500 tanks and armored vehicles\n",
            "* 100 artillery pieces and multiple rocket launchers\n",
            "* 500 special forces and saboteurs\n",
            "\n",
            "Moldovan Government Forces:\n",
            "\n",
            "* 20,000 troops, including ground troops, air force, and naval assets\n",
            "* 100 tanks and armored vehicles\n",
            "* 50 artillery pieces and multiple rocket launchers\n",
            "* 200 special forces and saboteurs\n",
            "\n",
            "Background:\n",
            "\n",
            "In the months leading up to the invasion, Russia has been building up its military presence along Moldova's borders. Russian President Vladimir Putin has made several public statements threatening to take action against Moldova, accusing the country of being a \"threat to Russian security\" and claiming that Moldova's pro-Western government is illegitimate.\n",
            "\n",
            "On March 20, 2023, Russian forces launch a massive assault on Moldova, targeting key cities and military installations across the country. The Russian air force is particularly effective, with bombers and fighter jets pounding Moldova's air defenses and ground attack aircraft attacking key military targets.\n",
            "The Russian ground forces quickly make gains, advancing rapidly across the country and capturing several key cities, including the capital of Chisinau. The Moldovan government and its forces are quickly overwhelmed, and the country's military is unable to mount an effective resistance against the Russian onslaught.\n",
            "The Russian special forces and saboteurs also play a key role in the invasion, conducting raids and sabotage missions against Moldova's military and civilian infrastructure.\n",
            "\n",
            "As the invasion progresses, the Russian military begins to consolidate its gains, establishing control over key cities and infrastructure, and rounding up opposition leaders and dissidents. The Russian government also begins to establish a puppet government in Moldova, with loyalists of Moscow taking key positions in the country's political and military leadership.\n",
            "\n",
            "International Response:\n",
            "\n",
            "The international community is shocked and outraged by Russia's invasion of Moldova, with the United States and other Western countries condemning the action as a clear violation of Moldova's sovereignty and international law. The United Nations Security Council holds an emergency meeting to discuss the situation and consider possible responses to Russia's aggression.\n",
            "However, the international community's ability to respond to the invasion is limited by the ongoing conflict in Ukraine and the broader geopolitical situation in Eastern Europe. Many countries are wary of taking on Russia to directly, fearing that this could lead to a wider conflict.\n",
            "In the aftermath of the invasion, Moldova's pro-Western government is forced to flee the country, and the Russian puppet government takes control. The country's economy is severely damaged, and Moldova's position in the world is significantly weakened.\n",
            "Conclusion:\n",
            "The potential Russian invasion of Moldova highlights the ongoing tensions between Russia and the West, and the fragility of the international order in Eastern Europe. The invasion also underscores the need for a comprehensive and cohesive approach to security in the region, one that takes into account the complexities of the geopolitical situation and the threatens posed by Russia.\n",
            "It is important for the international community to take a strong stance against Russia's aggression, and to provide support to Moldova in its time of need. The international community must also continue to work towards a peaceful resolution to the conflict in Ukraine, and towards a broader settlement of the geopolitical situation in Eastern Europe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(tokenizer,\n",
        "           query_pipeline,\n",
        "           questions[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8u-mOxUIPdj",
        "outputId": "d868648a-8963-4f04-f4a3-8251dd6a98a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test inference: 112.794 sec.\n",
            "Result: Now identify one person in this scenario who would be a potential HUMINT source for the US Intelligence Community and write a short source dossier. Be sure to include their placement and access.\n",
            "\n",
            "Scenario: A senior engineer at a major technology company is approached by a rival company to steal trade secrets. The engineer is offered a large sum of money and a promotion to a high-level position at the rival company.\n",
            "\n",
            "Potential HUMINT source: The senior engineer, John Smith.\n",
            "\n",
            "Source dossier:\n",
            "\n",
            "Name: John Smith\n",
            "\n",
            "Placement: Senior engineer at a major technology company\n",
            "\n",
            "Access: Top-secret research and development projects, including cutting-edge technology and innovative products\n",
            "\n",
            "Skills: Extensive knowledge of engineering, technology, and product development\n",
            "\n",
            "Background: John Smith has been with the company for 15 years, starting as an entry-level engineer and working his way up to a senior position. He has a deep understanding of the company's research and development projects and has worked closely with the company's executives.\n",
            "\n",
            "Motivation: John Smith is motivated by the promise of a large sum of money and a promotion to a high-level position at the rival company. He is also eager to prove himself and advance his career.\n",
            "\n",
            "Potential for exploitation: John Smith has access to top-secret research and development projects, including cutting-edge technology and innovative products. He could potentially provide valuable information on these projects, including design specifications, testing results, and production plans.\n",
            "\n",
            "Risks: John Smith could be exposed to security risks if caught stealing trade secrets. He could also face legal consequences if caught by the company.\n",
            "\n",
            "Strengths: John Smith has extensive knowledge of engineering, technology, and product development, making him a valuable asset for the US Intelligence Community. He also has a strong motivation to prove himself and advance his career.\n",
            "\n",
            "Weaknesses: John Smith's motivation could be compromised if he is caught by the company or if he realizes the consequences of his actions. He could also be vulnerable to coercion or manipulation if he is approached by the rival company.\n",
            "\n",
            "In conclusion, John Smith is a potential HUMINT source for the US Intelligence Community, given his extensive knowledge of engineering, technology, and product development, and his strong motivation to prove himself and advance his career. However, he also poses a security risk if caught stealing trade secrets, and could be vulnerable to coercion or manipulation if approached by the rival company. It is important to carefully assess and evaluate the potential risks and benefits of utilizing John Smith as a HUMINT source before making a decision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(tokenizer,\n",
        "           query_pipeline,\n",
        "           questions[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2g09XI1IPt7",
        "outputId": "d8c9b574-2b3e-45a5-ef8d-e4a3d2ec8fd0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test inference: 85.351 sec.\n",
            "Result: Write me three short intelligence information reports that came from that source about various events in the scenario.\n",
            "\n",
            "Intelligence Information Report 1:\n",
            "Title: Allied Forces to Launch Offensive in Eastern Europe\n",
            "\n",
            "Date: March 20, 1944\n",
            "\n",
            "Location: Berlin, Germany\n",
            "\n",
            "Summary: According to high-ranking sources within the German military, the Allied forces are planning to launch a large-scale offensive in Eastern Europe in the coming weeks. The offensive is expected to target key German military positions and infrastructure, including major cities and transportation hubs. The Allies have assembled a significant force, including ground troops, air support, and naval assets, and are expected to make a major push in the coming weeks.\n",
            "\n",
            "Intelligence Information Report 2:\n",
            "Title: Japanese Diplomats in Europe Under Investigation\n",
            "\n",
            "Date: April 10, 1944\n",
            "\n",
            "Location: Tokyo, Japan\n",
            "\n",
            "Summary: Sources within the Japanese government have revealed that several high-ranking diplomats stationed in Europe are under investigation for suspected espionage activities. The diplomats, who are believed to be working closely with German officials, are suspected of passing sensitive information back to Tokyo. The Japanese government has yet to confirm the allegations, but several of the accused diplomats have already been recalled to Japan for questioning.\n",
            "\n",
            "Intelligence Information Report 3:\n",
            "Title: U-Boat Activity Increases in Atlantic\n",
            "\n",
            "\n",
            "Date: May 15, 1944\n",
            "\n",
            "Location: London, United Kingdom\n",
            "\n",
            "Summary: Reports from multiple sources indicate that U-boat activity in the Atlantic has increased significantly in recent weeks. Multiple sightings of U-boats have been reported off the coasts of both the United States and the United Kingdom, with several attacks on Allied shipping reported. The surge in U-boat activity is believed to be a response to the ongoing Allied offensive in North Africa, which has disrupted Axis supply lines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(tokenizer,\n",
        "           query_pipeline,\n",
        "           questions[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFvj19rpIQFb",
        "outputId": "4a8638c7-70d7-44b7-e4d7-3e63f933fc57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test inference: 49.962 sec.\n",
            "Result: Add dates and times for the intelligence reports.\n",
            "\n",
            "The intelligence reports are:\n",
            "\n",
            "1. 2022-01-01 00:00:00 - The enemy is preparing to launch a surprise attack on our position.\n",
            "2. 2022-01-02 00:00:00:00 - The enemy has launched a surprise attack on our position, but we have repelled the attack.\n",
            "3. 2022-01-03 00:00:00:00 - The enemy is preparing to launch a counterattack on our position.\n",
            "4. 2022-01-04 00:00:00:00 - The enemy has launched a counterattack on our position, but we have repelled the attack.\n",
            "5. 2022-01-05 00:00:00:00 - The enemy is preparing to launch a full-scale attack on our position.\n",
            "\n",
            "Please provide the dates and times for the intelligence reports.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRCfy9bnKY7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}